<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition System</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.14/dist/face-api.esm.min.js"></script>
</head>
<body>
    <h1>Face Recognition System</h1>
    <video id="video" width="640" height="480" autoplay muted></video>
    <button onclick="startRecognition()">Start Recognition</button>
    <div id="result"></div>

    <script>
        const video = document.getElementById('video');
        const knownDescriptors = [];

        // Start video stream
        async function setupWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;
        }

        // Load the face-api.js models
        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('https://erabhishekkumar.github.io/models/ssd_mobilenetv1');
await faceapi.nets.faceLandmark68Net.loadFromUri('https://erabhishekkumar.github.io/models/face_landmark_68');
await faceapi.nets.faceRecognitionNet.loadFromUri('https://erabhishekkumar.github.io/models/face_recognition');

        }

        // Fetch all image file names from the GitHub students folder
        async function loadKnownDescriptors() {
            const studentFolderUrl = 'https://api.github.com/repos/ErAbhishekKumar/erabhishekkumar.github.io/contents/students';

            // Fetch list of files in students folder
            const response = await fetch(studentFolderUrl);
            const files = await response.json();

            for (const file of files) {
                if (file.type === 'file' && file.name.endsWith('.jpg')) {  // Only .jpg files
                    const imageUrl = file.download_url;
                    const response = await fetch(imageUrl);
                    const img = await faceapi.bufferToImage(await response.arrayBuffer());
                    const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
                    if (fullFaceDescription) {
                        knownDescriptors.push({ descriptor: fullFaceDescription.descriptor, name: file.name });
                    }
                }
            }
        }

        // Recognize face and match with uploaded photos
        async function startRecognition() {
            const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
            if (detections.length > 0) {
                const descriptions = detections.map(fd => fd.descriptor);

                // Compare with known descriptors
                const match = faceapi.findBestMatch(descriptions[0], knownDescriptors.map(kd => kd.descriptor));

                if (match) {
                    const matchedData = knownDescriptors[match._index];
                    const [regNo, ...nameParts] = matchedData.name.split('_');
                    const fullName = nameParts.join(' ');

                    // Display matched name and registration number
                    document.getElementById('result').innerText = `Matched with: Registration No: ${regNo}, Name: ${fullName}`;
                }
            } else {
                document.getElementById('result').innerText = 'No face detected';
            }
        }

        // Initialize the webcam and models
        setupWebcam();
        loadModels();
        loadKnownDescriptors();  // Pre-load known descriptors
    </script>
</body>
</html>
