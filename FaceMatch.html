<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition System</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
</head>
<body>
    <h1>Face Recognition System</h1>
    <video id="video" width="640" height="480" autoplay muted></video>
    <button onclick="startRecognition()">Start Recognition</button>
    <div id="result"></div>

    <script>
        const video = document.getElementById('video');
        const knownDescriptors = [];

        // Start video stream
        async function setupWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;
        }

        // Load the face-api.js models
        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        }

        // Load known face descriptors from GitHub (fetch from your GitHub repository)
        async function loadKnownDescriptors() {
            // List of all photos in your GitHub students folder
            const photoNames = [
                '21101157001_Abhishek_Kumar.jpg',
                '21101157002_Sudhir_Singh.jpg',
                // Add more file names here as needed
            ];

            for (const photo of photoNames) {
                const imageUrl = `https://raw.githubusercontent.com/ErAbhishekKumar/erabhishekkumar.github.io/main/students/${photo}`;
                const response = await fetch(imageUrl);
                const img = await faceapi.bufferToImage(await response.arrayBuffer());
                const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
                if (fullFaceDescription) {
                    knownDescriptors.push({ descriptor: fullFaceDescription.descriptor, name: photo.split('_').slice(1).join(' ') });
                }
            }
        }

        // Recognize face and match with uploaded photos
        async function startRecognition() {
            const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
            if (detections.length > 0) {
                const descriptions = detections.map(fd => fd.descriptor);

                // Compare with known descriptors
                const match = faceapi.findBestMatch(descriptions[0], knownDescriptors.map(kd => kd.descriptor));

                if (match) {
                    const matchedData = knownDescriptors[match._index];
                    const [regNo, ...nameParts] = matchedData.name.split('_');
                    const fullName = nameParts.join(' ');

                    // Display matched name and registration number
                    document.getElementById('result').innerText = `Matched with: Registration No: ${regNo}, Name: ${fullName}`;
                }
            } else {
                document.getElementById('result').innerText = 'No face detected';
            }
        }

        // Initialize the webcam and models
        setupWebcam();
        loadModels();
        loadKnownDescriptors();  // Pre-load known descriptors
    </script>
</body>
</html>
